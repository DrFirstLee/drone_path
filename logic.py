


@app.post("/drone_analyze")
async def drone_analyze(file: UploadFile = File(...)):
    print(f"Drone Analysis Request: {file.filename}")
    
    # ì„ì‹œ ë””ë ‰í† ë¦¬ ìƒì„±í•˜ì—¬ ì²˜ë¦¬
    with tempfile.TemporaryDirectory() as temp_dir:
        temp_file_path = os.path.join(temp_dir, file.filename)
        
        # íŒŒì¼ ì €ì¥
        content = await file.read()
        with open(temp_file_path, "wb") as f:
            f.write(content)
            
        target_file = temp_file_path
        base_dir = temp_dir
        
        print(f"Reading file: {target_file}")
        
        column_names = [
            'Time', 'Longitude', 'Latitude', 'Altitude', 
            'Roll', 'Pitch', 'Yaw', 
            'Mag1_X', 'Mag1_Y', 'Mag1_Z', 
            'Mag2_X', 'Mag2_Y', 'Mag2_Z'
        ]
        

        try:
            df = pd.read_csv(target_file, header=None)
            
            # Timestamp ì»¬ëŸ¼ ì°¾ê¸° ë° ë°ì´í„° ì‹œí”„íŠ¸ ì²˜ë¦¬
            valid_start_idx = -1
            
            # ì²˜ìŒ 5ê°œ ì»¬ëŸ¼ ì •ë„ë§Œ ê²€ì‚¬ (ë„ˆë¬´ ë’¤ì— ìˆì§€ëŠ” ì•Šì„ ê²ƒì´ë¼ ê°€ì •)
            check_limit = min(df.shape[1], 5)
            
            for i in range(check_limit):
                sample_val = df.iloc[0, i]
                numeric_val = float(sample_val)
                if numeric_val <= 500000:
                    continue
                else:
                    valid_start_idx = i
                    print(f"Timestamp column found at index {i}")
                    break

            if valid_start_idx == -1:
                raise ValueError("Timestamp column not found")

            
            if valid_start_idx != -1:
                # ìœ íš¨í•œ ì‹œì‘ ì¸ë±ìŠ¤ ë°œê²¬ ì‹œ, í•´ë‹¹ ì¸ë±ìŠ¤ë¶€í„° 13ê°œ ì»¬ëŸ¼ ì‚¬ìš©
                end_idx = valid_start_idx + len(column_names)
                if df.shape[1] >= end_idx:
                    df = df.iloc[:, valid_start_idx:end_idx]
                    df.columns = column_names
                else:
                    # ì»¬ëŸ¼ì´ ë¶€ì¡±í•œ ê²½ìš° ê°€ëŠ¥í•œ ë§Œí¼ë§Œ ê°€ì ¸ì˜´
                    df = df.iloc[:, valid_start_idx:]
                    df.columns = column_names[:df.shape[1]]
            else:
                print("Could not find a valid timestamp column. Defaulting to column 0.")
                # ê¸°ì¡´ ë¡œì§ (ì»¬ëŸ¼ 0ë¶€í„° ì‹œì‘)
                if df.shape[1] >= len(column_names):
                    current_cols = column_names + [f"Extra_{i}" for i in range(len(column_names), df.shape[1])]
                    df.columns = current_cols
                else:
                    df.columns = column_names[:df.shape[1]]
                
            print("Data loaded. Applying segmentation...")

            # 3. Feature Engineering
            # Yaw Unwrapping
            yaw_rad = np.deg2rad(df['Yaw'])
            df['Yaw_unwrap'] = np.rad2deg(np.unwrap(yaw_rad))
            
            # Improved Feature Engineering for robust Turn Detection
            # Improved Feature Engineering for robust Turn Detection
            window_size = 30
            
            # 1. IMU-based Features
            # Yaw (Heading)
            df['Yaw_diff'] = df['Yaw_unwrap'].diff().fillna(0).abs()
            df['Yaw_rate'] = df['Yaw_diff'].rolling(window=window_size, center=True).mean().fillna(0)
            df['Yaw_std'] = df['Yaw_unwrap'].rolling(window=window_size, center=True).std().fillna(0)
            
            # Roll (Banking)
            df['Roll_abs'] = df['Roll'].abs().rolling(window=window_size, center=True).mean().fillna(0)
            
            # 2. Centripetal Acceleration (v * omega)
            # This helps distinguish 'High Speed Turns' (High Centripetal) vs 'Straight' (Low Centripetal)
            # and 'Stationary Turns' (Low Centripetal, but High Yaw Rate).
            if 'Latitude' in df.columns and 'Longitude' in df.columns:
                R = 6371000 # Earth radius
                lat_rad = np.deg2rad(df['Latitude'])
                lon_rad = np.deg2rad(df['Longitude'])
                
                # Approximate distance per sample (meter)
                # dy = R * dLat
                # dx = R * dLon * cos(Lat)
                dx = R * lon_rad.diff().fillna(0) * np.cos(lat_rad.mean())
                dy = R * lat_rad.diff().fillna(0)
                ds = np.sqrt(dx**2 + dy**2)
                
                # Speed proxy (ds per sample)
                df['Speed_proxy'] = ds.rolling(window=window_size, center=True).mean().fillna(0)
                
                # Centripetal Acceleration ~ Speed * YawRate
                # Note: Yaw_rate is deg/sample, Speed is m/sample. Product is proportional to m/s^2.
                df['Centripetal_Acc'] = df['Speed_proxy'] * df['Yaw_rate']
            else:
                df['Speed_proxy'] = 0
                df['Centripetal_Acc'] = 0
            
            # Combine features
            # Yaw_rate: Detects sharp/stationary turns
            # Centripetal_Acc: Detects high-speed/wide turns
            # Roll_abs: Auxiliary indicator for banked turns
            feature_cols = ['Yaw_rate', 'Yaw_std', 'Roll_abs', 'Centripetal_Acc']
            df[feature_cols] = df[feature_cols].fillna(0)
            
            # Scaling & Clustering
            scaler = StandardScaler()
            X_scaled = scaler.fit_transform(df[feature_cols])
            
            # HMM (Hidden Markov Model) for Time-Series Continuity
            # Ideally better than K-Means for sequential data as it models transitions.
            from hmmlearn import hmm
            print("Using GaussianHMM for segmentation...")
            
            # 2 states: Straight vs Turn
            # covariance_type="diag" is generally robust for this
            model = hmm.GaussianHMM(n_components=2, covariance_type="diag", n_iter=100, random_state=42)
            model.fit(X_scaled)
            
            # Predict states
            df['State_Raw'] = model.predict(X_scaled)
            
            # Identify which state is 'Turn'
            # Check the mean of features for each state. The state with higher values is likely 'Turn'.
            state_means = []
            for s in range(2):
                # Average feature value for this state
                state_mean = np.mean(X_scaled[df['State_Raw'] == s], axis=0)
                state_means.append(np.sum(state_mean)) # Sum of standardized features
            
            turn_label = np.argmax(state_means)

            # try:
            #     from hmmlearn import hmm
            #     print("Using GaussianHMM for segmentation...")
                
            #     # 2 states: Straight vs Turn
            #     # covariance_type="diag" is generally robust for this
            #     model = hmm.GaussianHMM(n_components=2, covariance_type="diag", n_iter=100, random_state=42)
            #     model.fit(X_scaled)
                
            #     # Predict states
            #     df['State_Raw'] = model.predict(X_scaled)
                
            #     # Identify which state is 'Turn'
            #     # Check the mean of features for each state. The state with higher values is likely 'Turn'.
            #     state_means = []
            #     for s in range(2):
            #         # Average feature value for this state
            #         state_mean = np.mean(X_scaled[df['State_Raw'] == s], axis=0)
            #         state_means.append(np.sum(state_mean)) # Sum of standardized features
                
            #     turn_label = np.argmax(state_means)
                
            # except ImportError:
            #     print("hmmlearn not found, falling back to K-Means...")
            #     # Fallback to K-Means if hmmlearn is missing
            #     kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)
            #     df['State_Raw'] = kmeans.fit_predict(X_scaled)
                
            #     cluster_centers = kmeans.cluster_centers_
            #     cluster_magnitudes = np.sum(cluster_centers, axis=1)
            #     turn_label = np.argmax(cluster_magnitudes)
            
            # 0: Straight, 1: Turn ìœ¼ë¡œ ë¼ë²¨ ì •ê·œí™”
            df['State'] = df['State_Raw'].apply(lambda x: 1 if x == turn_label else 0)
            
            # [DEBUG] RAW Clustering Visualization Mode
            # Bypassing complex post-processing to see raw HMM/KMeans output.
            
            # 4. Smoothing (ë…¸ì´ì¦ˆ ì œê±°) - Skipped
            # smooth_window = 10
            # df['State_Smooth'] = df['State'].rolling(window=smooth_window, center=True).mean()
            # df['State_Smooth'] = df['State_Smooth'].apply(lambda x: 1 if x > 0.5 else 0).fillna(0).astype(int)
            df['State_Smooth'] = df['State'] # Use Raw State
            
            # 5. Segment Identification & Merging (êµ¬ê°„ ë‚˜ëˆ„ê¸° ë° ë³‘í•©) - Simplified
            df['Segment_Change'] = df['State_Smooth'].diff().fillna(0).abs()
            # Simple cumulative sum to create unique IDs for every state change
            df['Final_Segment_ID'] = df['Segment_Change'].cumsum().astype(int)

            # 6. Rotate_Error íŒë³„: PCA ì„ í˜•ì„± + Yaw ì´ ë³€í™”ëŸ‰ ë³µí•© íŒë‹¨
            #
            #  [ë¬¸ì œ] 130Â° êº¾ì„(í—¤ì–´í•€/Vì) ê²½ë¡œëŠ” ë‘ íŒ”ì´ ë°˜ëŒ€ ë°©í–¥ì´ë¼
            #         PCA 1st ì„±ë¶„ì´ ë†’ê²Œ ë‚˜ì™€ ì§ì„ ìœ¼ë¡œ ì˜¤íŒë  ìˆ˜ ìˆìŒ.
            #
            #  [í•´ê²°] GPS ì„ í˜•ì„±ì´ ë†’ì•„ë„ Yaw ì´ ë³€í™”ëŸ‰ì´ í¬ë©´ ì‹¤ì œ íšŒì „ìœ¼ë¡œ ì¸ì •.
            #         â†’ ë‘ ì¡°ê±´ì´ ëª¨ë‘ ì„±ë¦½í•´ì•¼ Rotate_Error:
            #           (1) PCA ì„ í˜•ì„± ë†’ìŒ (GPS ê²½ë¡œê°€ ì§ì„ í˜•)
            #           (2) Yaw ì´ ë³€í™” ì‘ìŒ (ë°©í–¥ì´ ê±°ì˜ ì•ˆ ë°”ë€œ)
            #
            # State_Final: 0=Straight, 1=Rotate, 3=Rotate_Error
            from sklearn.decomposition import PCA as _PCA

            def is_linear_path(lats, lons, linearity_threshold=0.98):
                """GPS ì¢Œí‘œ ì§‘í•©ì— PCAë¥¼ ì ìš©í•˜ì—¬ ê²½ë¡œì˜ ì„ í˜•ì„±ì„ ì¸¡ì •.

                ë°˜í™˜ê°’: (is_linear (bool), pca_ratio (float))
                """
                if len(lats) < 6:
                    return False, 0.0

                R = 6371000.0
                lat_rad = np.deg2rad(np.mean(lats))
                xs = np.deg2rad(lons) * R * np.cos(lat_rad)
                ys = np.deg2rad(lats) * R
                coords = np.column_stack([xs, ys])

                span = np.ptp(coords, axis=0)
                if np.max(span) < 1.0:  # ì´ë™ ë°˜ê²½ 1m ë¯¸ë§Œ â†’ ì œìë¦¬
                    return True, 1.0

                pca = _PCA(n_components=2)
                pca.fit(coords)
                ratio = pca.explained_variance_ratio_[0]
                return ratio >= linearity_threshold, ratio

            df['State_Final'] = df['State_Smooth'].copy()  # ê¸°ë³¸ê°’ ë³µì‚¬ (0=Straight)
            df['PCA_Ratio'] = 0.0

            if 'Latitude' in df.columns and 'Longitude' in df.columns:
                rotate_seg_ids = df[df['State_Smooth'] == 1]['Final_Segment_ID'].unique()
                for rid in rotate_seg_ids:
                    seg_mask = (df['Final_Segment_ID'] == rid)
                    seg = df[seg_mask]
                    lats = seg['Latitude'].values
                    lons = seg['Longitude'].values

                    gps_is_linear, pca_ratio = is_linear_path(lats, lons)
                    df.loc[seg_mask, 'PCA_Ratio'] = pca_ratio

                    # Yaw ì´ ë³€í™”ëŸ‰: í•´ë‹¹ êµ¬ê°„ì˜ unwrapped yaw ë²”ìœ„
                    # - ì§ì„  ë¹„í–‰: yaw ê±°ì˜ ì•ˆ ë³€í•¨ â†’ ì‘ì€ ê°’
                    # - 90Â°/130Â° ì‹¤ì œ í„´: yaw í¬ê²Œ ë³€í•¨ â†’ í° ê°’
                    if 'Yaw_unwrap' in seg.columns and len(seg) > 0:
                        yaw_change = seg['Yaw_unwrap'].max() - seg['Yaw_unwrap'].min()
                    else:
                        yaw_change = 0.0

                    # [íŒì •]
                    # 1. ì›ë³¸ ë¡œì§ ì ìš© (ê¸°ë³¸) 
                    YAW_CHANGE_THRESHOLD = 45.0  # ë„(Â°).
                    
                    # 2. ë¨¼ì € Rotate_Error ì—¬ë¶€ë¥¼ íŒë³„í•©ë‹ˆë‹¤. (Yawê°€ ê±°ì˜ ë³€í•˜ì§€ ì•Šê³  GPS ê¶¤ì ë„ ì§ì„ ì¼ ë•Œ)
                    if gps_is_linear and yaw_change < YAW_CHANGE_THRESHOLD:
                        df.loc[seg_mask, 'State_Final'] = 3  # Rotate_Error (ì˜¤ë¶„ë¥˜)
                    else:
                        if gps_is_linear:
                            df.loc[seg_mask, 'State_Final'] = 2  # Rotate_Line (ì§ì„ ì²˜ëŸ¼ ë³´ì´ëŠ” íšŒì „)
                        else:
                            df.loc[seg_mask, 'State_Final'] = 1  # ì •ìƒ Rotate
            else:
                df.loc[df['State_Smooth'] == 1, 'State_Final'] = 1
                
            # --- ì„¸ê·¸ë¨¼íŠ¸ ID ì¬ê³„ì‚° ---
            # ì„œë¸Œ í´ëŸ¬ìŠ¤í„°ë§ìœ¼ë¡œ ì¸í•´ State_Finalì´ ìª¼ê°œì¡Œìœ¼ë¯€ë¡œ, Final_Segment_IDë¥¼ ìƒˆë¡œ ë¶€ì—¬í•©ë‹ˆë‹¤.
            df['Segment_Change_Final'] = (df['State_Final'] != df['State_Final'].shift(1)).astype(int)
            df['Final_Segment_ID'] = df['Segment_Change_Final'].cumsum().astype(int)


            # 7. Line â†” Rotate_Error/Rotate_Line ì²´ì¸ ë³‘í•©
            #    ì‹¤ì œ Rotate(1)ë¡œ ëŠê¸°ì§€ ì•ŠëŠ” í•œ, {Line(0), Rotate_Line(2), Rotate_Error(3)} ì¸ì ‘ êµ¬ê°„ë“¤ì„
            #    í•˜ë‚˜ì˜ "run"ìœ¼ë¡œ ë¬¶ì–´ì„œ ë³‘í•©.
            #
            #    ë³‘í•© ê·œì¹™:
            #      - run ë‚´(1ë¡œ ëŠê¸°ê¸° ì „ê¹Œì§€ì˜ êµ¬ê°„)ì— Line(0)ì´ í•˜ë‚˜ë¼ë„ ì¡´ì¬í•œë‹¤ë©´,
            #        ê·¸ run ì•ˆì— ìˆëŠ” ëª¨ë“  2ì™€ 3ì€ ì‚¬ì‹¤ìƒ Lineì˜ ì—°ì¥ì„ ì´ë¯€ë¡œ ëª¨ë‘ Line(0)ìœ¼ë¡œ í†µí•©í•œë‹¤.
            #      - ë§Œì•½ run ì•ˆì— Line(0)ì´ ì•„ì˜ˆ ì—†ë‹¤ë©´ (ì˜ˆ: ë¶€ë¶„ì ìœ¼ë¡œ 2ë‚˜ 3ë§Œ ìˆëŠ” ê²½ìš°) ê·¸ëŒ€ë¡œ ë‘”ë‹¤.

            # ì„¸ê·¸ë¨¼íŠ¸ ìˆœì„œ ì¶”ì¶œ (ì›ë³¸ ì¸ë±ìŠ¤ ê¸°ë°˜ ì‹œê°„ ìˆœ ì •ë ¬)
            seg_order_df = (
                df[df['Final_Segment_ID'] >= 0]
                .groupby('Final_Segment_ID')
                .agg(
                    state_final=('State_Final', 'first'),
                    first_idx=('Final_Segment_ID', lambda x: x.index.min())
                )
                .reset_index()
                .sort_values('first_idx')
            )
            ordered_segs = list(zip(
                seg_order_df['Final_Segment_ID'].tolist(),
                seg_order_df['state_final'].tolist()
            ))  # [(seg_id, state_final), ...]

            # ì‹¤ì œ Rotate(1) ê²½ê³„ë¡œ run ë¶„ë¦¬
            runs = []
            current_run = []
            for seg_id, state in ordered_segs:
                if state in (0, 2, 3):
                    current_run.append((seg_id, state))
                else:  # state == 1: ì‹¤ì œ Rotate â†’ í˜„ì¬ run ì¢…ë£Œ
                    if current_run:
                        runs.append(current_run)
                        current_run = []
                    runs.append([(seg_id, state)])  # Rotate ìì²´ëŠ” ë‹¨ë… run
            if current_run:
                runs.append(current_run)

            # ê° run ë‚´ì—ì„œ Line(0)ì´ í•˜ë‚˜ë¼ë„ ìˆë‹¤ë©´, 
            # ì¸ì ‘í•œ Rotate_Line(2)ì™€ Rotate_Error(3)ë¥¼ ëª¨ë‘ í•´ë‹¹ Lineìœ¼ë¡œ ë³‘í•©í•©ë‹ˆë‹¤.
            # (Sub-clusteringìœ¼ë¡œ ì¸í•´ 1-2-0 ì²˜ëŸ¼ ì˜ë¦° ê²½ìš°ì—ë„ 2ê°€ 0ìœ¼ë¡œ ë³‘í•©ë˜ë„ë¡ í•¨)
            merge_ops = {}  # {old_seg_id: new_seg_id}
            for run in runs:
                # Rotate(1) ë‹¨ë… runì´ë©´ ìŠ¤í‚µ
                if len(run) == 1 and run[0][1] == 1:
                    continue

                line_positions = [i for i, (_, st) in enumerate(run) if st == 0]

                # Run ë‚´ì— Line(0)ì´ ì•„ì˜ˆ ì—†ìœ¼ë©´ ë³‘í•© ëŒ€ìƒ ì—†ìŒ (ì˜ˆ: [2], [3], [2, 3] ë“± ì„œë¡œë“¤ë§Œ ìˆëŠ” ê²½ìš°)
                if len(line_positions) == 0:
                    continue

                # Run ë‚´ì— Line(0)ì´ í•˜ë‚˜ë¼ë„ ìˆë‹¤ë©´, Run ì „ì²´ ìš”ì†Œë¥¼ ê°€ì¥ ì²«ë²ˆì§¸ Lineì˜ IDë¡œ ë³‘í•©
                target_id = run[line_positions[0]][0]

                for old_id, _ in run:
                    if old_id != target_id:
                        merge_ops[old_id] = target_id

            # ë³‘í•© ì ìš©
            n_merged = 0
            all_target_ids = set(merge_ops.values())
            for old_id, new_id in merge_ops.items():
                df.loc[df['Final_Segment_ID'] == old_id, 'Final_Segment_ID'] = new_id
                n_merged += 1

            # ë³‘í•©ëœ ê·¸ë£¹ ë‚´ ë‚¨ì€ Error/Line íŒë‹¨ êµ¬ê°„ë“¤ì„ Line(0)ìœ¼ë¡œ êµì •
            for tid in all_target_ids:
                df.loc[(df['Final_Segment_ID'] == tid) & (df['State_Final'].isin([2, 3])), 'State_Final'] = 0

            if n_merged > 0:
                print(f"[Merge] {n_merged}ê°œ ì„¸ê·¸ë¨¼íŠ¸ë¥¼ Lineìœ¼ë¡œ ë³‘í•©í–ˆìŠµë‹ˆë‹¤.")
                
            # ë³‘í•© ì´í›„ ì¤‘ê°„ì— ê±´ë„ˆë›´(ì´ë¹¨ ë¹ ì§„) ì„¸ê·¸ë¨¼íŠ¸ IDë“¤ì„ 1ë²ˆë¶€í„° ì°¨ë¡€ëŒ€ë¡œ ì¬ì •ë ¬í•©ë‹ˆë‹¤.
            alive_seg_ids = sorted(df[df['Final_Segment_ID'] != -1]['Final_Segment_ID'].unique())
            id_mapping = {old_id: new_idx for new_idx, old_id in enumerate(alive_seg_ids, start=1)}
            df.loc[df['Final_Segment_ID'] != -1, 'Final_Segment_ID'] = df.loc[df['Final_Segment_ID'] != -1, 'Final_Segment_ID'].map(id_mapping).astype(int)
            
            # 7. ì§€ë„ ì‹œê°í™”
            if 'Latitude' in df.columns and 'Longitude' in df.columns:
                center_lat = df['Latitude'].mean()
                center_lon = df['Longitude'].mean()
                m = folium.Map(location=[center_lat, center_lon], zoom_start=16)
                
                # ì „ì²´ ê²½ë¡œë¥¼ ì—°í•œ íšŒìƒ‰ìœ¼ë¡œ í‘œì‹œ (ë°°ê²½)
                all_coords = df[['Latitude', 'Longitude']].values.tolist()
                folium.PolyLine(
                    locations=all_coords,
                    color="#000000", 
                    weight=5,
                    opacity=0.5,
                    tooltip="Original Path"
                ).add_to(m)
                
                # ë‹¤ì–‘í•œ ìƒ‰ìƒ íŒ”ë ˆíŠ¸ (ê²€ì •ìƒ‰ ë°°ê²½ê³¼ í™•ì‹¤íˆ êµ¬ë¶„ë˜ëŠ” ë°ê³  ì„ ëª…í•œ ìƒ‰ìƒ ìœ„ì£¼)
                colors = [
                    '#FF0000', # Red
                    '#00FF00', # Lime
                    '#0000FF', # Blue
                    '#FFFF00', # Yellow
                    '#FF00FF', # Magenta
                    '#00FFFF', # Cyan
                    '#FF8000', # Orange
                    '#0080FF', # Azure
                    '#FF0080', # Deep Pink
                    '#80FF00', # Chartreuse
                    '#00FF80', # Spring Green
                    '#FF4040', # Light Red
                    '#4040FF', # Light Blue
                    '#FFD700', # Gold
                    '#ADFF2F', # Green Yellow
                    '#FF69B4', # Hot Pink
                    '#1E90FF', # Dodger Blue
                    '#DC143C', # Crimson
                ]
                
                sorted_seg_ids = sorted(df[df['Final_Segment_ID'] != -1]['Final_Segment_ID'].unique())
                
                for seg_id in sorted_seg_ids:
                    group = df[df['Final_Segment_ID'] == seg_id]
                    coords = group[['Latitude', 'Longitude']].values.tolist()

                    # State_Final ê¸°ì¤€ìœ¼ë¡œ ì„¸ê·¸ë¨¼íŠ¸ íƒ€ì… ê²°ì •
                    # 0=Straight, 1=Rotate, 2=Rotate_Line, 3=Rotate_Error
                    seg_state_final = group['State_Final'].iloc[0] if 'State_Final' in group.columns else group['State_Smooth'].iloc[0]

                    if seg_state_final == 0:
                        type_str = "Straight"
                        label_prefix = "Line"
                        color_idx = seg_id % len(colors)
                        color = colors[color_idx]
                        weight = 3
                        opacity = 0.8
                        dash_array = None
                    elif seg_state_final == 1:
                        type_str = "Rotate"
                        label_prefix = "Rotate"
                        color_idx = seg_id % len(colors)
                        color = colors[color_idx]
                        weight = 5
                        opacity = 0.9
                        dash_array = '5, 5'
                    elif seg_state_final == 2:
                        type_str = "Rotate_Line"
                        label_prefix = "Rotate_Line"
                        color = '#9400D3'  # ëˆˆì— ë„ëŠ” ë³´ë¼ìƒ‰ìœ¼ë¡œ ì„¤ì •
                        weight = 5
                        opacity = 0.9
                        dash_array = '10, 5'  # ì ì„ ìœ¼ë¡œ êµ¬ë¶„
                    else:  # state == 3: Rotate_Error
                        type_str = "Rotate_Error"
                        label_prefix = "Rotate_Error"
                        color = '#FF6600'  # ëˆˆì— ë„ëŠ” ì£¼í™©ìƒ‰ìœ¼ë¡œ ê³ ì •
                        weight = 5
                        opacity = 0.9
                        dash_array = '10, 5'  # ë” ê¸´ ì ì„ ìœ¼ë¡œ êµ¬ë¶„

                    label_text = f"{label_prefix}-{seg_id}"
                    
                    if (seg_state_final != 0 )and 'PCA_Ratio' in group.columns:
                        pca_val = group['PCA_Ratio'].iloc[0]
                        label_text += f" (PCA: {pca_val:.3f})"

                    # --- [FIX] ì‹œê°„ ë¶ˆì—°ì† êµ¬ê°„ ê°ì§€ ë° ë¶„ë¦¬í•˜ì—¬ ê·¸ë¦¬ê¸° ---
                    # "ë™ê·¸ë€ ë¶€ë¶„ì´ ì™œ ì§ì„ í‘œí˜„ë˜ì§€" -> ë–¨ì–´ì ¸ ìˆëŠ” ê°™ì€ ID êµ¬ê°„ì„ ì´ì–´ì„œ ê·¸ë ¤ì„œ ë°œìƒí•˜ëŠ” ë¬¸ì œ í•´ê²°

                    # ê·¸ë£¹ ë‚´ì—ì„œ ì›ë˜ ì¸ë±ìŠ¤ë¥¼ ê°€ì ¸ì™€ì„œ ì°¨ì´ ê³„ì‚°
                    indices = group.index.values
                    if len(indices) > 0:
                        # ì¸ë±ìŠ¤ê°€ 1ë³´ë‹¤ í° ì°¨ì´ê°€ ë‚˜ë©´ ë¶ˆì—°ì†ìœ¼ë¡œ ê°„ì£¼
                        idx_diff = np.diff(indices)
                        split_locs = np.where(idx_diff > 1)[0] + 1

                        # ì„œë¸Œ ê·¸ë£¹ìœ¼ë¡œ ë¶„í• 
                        sub_groups_indices = np.split(indices, split_locs)

                        for sub_indices in sub_groups_indices:
                            if len(sub_indices) < 2: continue  # ì  1ê°œëŠ” ì„ ìœ¼ë¡œ ëª» ê·¸ë¦¼

                            sub_group = df.loc[sub_indices]
                            sub_coords = sub_group[['Latitude', 'Longitude']].values.tolist()

                            folium.PolyLine(
                                locations=sub_coords,
                                color=color,
                                weight=weight,
                                opacity=opacity,
                                dash_array=dash_array,
                                tooltip=f"ID {seg_id}: {type_str}"
                            ).add_to(m)

                            # ê° ì„œë¸Œ ê·¸ë£¹ì˜ ì‹œì‘ì ì— ì‘ì€ ë§ˆì»¤ í‘œì‹œ
                            folium.CircleMarker(
                                location=sub_coords[0],
                                radius=3 if seg_state_final == 3 else 2,
                                color=color,
                                fill=True,
                                popup=f"ID {seg_id} [{type_str}] part start"
                            ).add_to(m)

                    center_lat_g = group['Latitude'].mean()
                    center_lon_g = group['Longitude'].mean()

                    # Rotate_ErrorëŠ” í…ìŠ¤íŠ¸ ìƒ‰ìƒ ê°•ì¡° + âš ï¸ ì•„ì´ì½˜ ë¶™ì—¬ì„œ êµ¬ë¶„
                    if seg_state_final == 2:
                        label_html = f'<div style="font-size: 10pt; font-weight: bold; color: {color}; text-shadow: 1px 1px 2px white;">ğŸ”„ {label_text}</div>'
                    elif seg_state_final == 3:
                        label_html = f'<div style="font-size: 10pt; font-weight: bold; color: #FF6600; text-shadow: 1px 1px 2px white;">âš ï¸ {label_text}</div>'
                    else:
                        label_html = f'<div style="font-size: 10pt; font-weight: bold; color: {color}; text-shadow: 1px 1px 1px white;">{label_text}</div>'

                    folium.Marker(
                        location=[center_lat_g, center_lon_g],
                        icon=folium.DivIcon(
                            icon_size=(180, 36),
                            icon_anchor=(0, 0),
                            html=label_html
                        )
                    ).add_to(m)

                output_file = os.path.join(temp_dir, "flight_path_segmented.html")
                m.save(output_file)
                print(f"ì§€ë„ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {output_file}")
                
                # 7. ë¶„í• ëœ ë°ì´í„° ì €ì¥ (./splited) ë° Download Link ìƒì„±
                output_split_dir = os.path.join(temp_dir, "splited")
                if not os.path.exists(output_split_dir):
                    os.makedirs(output_split_dir)
                    
                csv_links = []
                
                # Sort group keys for better UI ordering
                sorted_groups = sorted(df[df['Final_Segment_ID'] != -1].groupby('Final_Segment_ID'), key=lambda x: x[0])
                
                for seg_id, group in sorted_groups:
                    # State_Final ê¸°ì¤€ìœ¼ë¡œ ë ˆì´ë¸” ê²°ì •: 0=Line, 1=Rotate, 2=Rotate_Line, 3=Rotate_Error
                    seg_state_final = group['State_Final'].iloc[0] if 'State_Final' in group.columns else group['State_Smooth'].iloc[0]
                    if seg_state_final == 0:
                        label_prefix = "Line"
                        link_style = "display:block; margin:5px 0; color:#333;"
                    elif seg_state_final == 1:
                        label_prefix = "Rotate"
                        link_style = "display:block; margin:5px 0; color:#0055aa; font-weight:bold;"
                    elif seg_state_final == 2:
                        label_prefix = "Rotate_Line"
                        link_style = "display:block; margin:5px 0; color:#9400D3; font-weight:bold;"
                    else:  # 3 = Rotate_Error
                        label_prefix = "Rotate_Error"
                        link_style = "display:block; margin:5px 0; color:#FF6600; font-weight:bold;"

                    file_name = f"{label_prefix}-{seg_id}.csv"
                    save_path = os.path.join(output_split_dir, file_name)

                    # Generate CSV content
                    csv_content = group.to_csv(index=True, header=True)

                    # Save for record
                    with open(save_path, "w", encoding='utf-8') as f:
                        f.write(csv_content)

                    # Create Data URI for download
                    b64_csv = base64.b64encode(csv_content.encode('utf-8')).decode('utf-8')
                    prefix_icon = "âš ï¸ " if seg_state_final == 3 else ("ğŸ”„ " if seg_state_final == 2 else "")
                    download_link = f'<a href="data:text/csv;base64,{b64_csv}" download="{file_name}" style="{link_style}">{prefix_icon}Download {file_name}</a>'
                    csv_links.append(download_link)
                
                # HTML íŒŒì¼ ì½ê¸° (ë°˜í™˜ìš©)
                with open(output_file, 'r', encoding='utf-8') as f:
                    html_content = f.read()

                # HTMLì— Download Panel ì¶”ê°€
                if csv_links:
                    download_panel = f"""
                    <div style="position: fixed; top: 10px; right: 10px; width: 250px; max-height: 80vh; overflow-y: auto; 
                                background-color: white; padding: 10px; border: 2px solid #ccc; z-index: 9999; box-shadow: 0 0 10px rgba(0,0,0,0.2);">
                        <h4>Segment CSV Downloads</h4>
                        {''.join(csv_links)}
                    </div>
                    """
                    # Insert before </body>
                    if "</body>" in html_content:
                        html_content = html_content.replace("</body>", f"{download_panel}</body>")
                    else:
                        html_content += download_panel

                return HTMLResponse(content=html_content)
                
        except Exception as e:
            print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
            return JSONResponse(status_code=500, content={"error": str(e)})

